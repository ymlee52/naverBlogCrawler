package crawling

import (
	"encoding/json"
	"fmt"
	"io"
	"log"
	"os"
	"path/filepath"
	"re_naverBlogCrawler/internal/utils"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
)

// BlogPost represents a blog post.
type BlogPost struct {
	ID          string        `json:"id"`
	Title       string        `json:"title"`
	Content     string        `json:"content"`
	Writer      string        `json:"writer"`
	WriteDate   string        `json:"write_date"`
	Comments    []BlogComment `json:"comments"`
	OriginalURL string        `json:"original_url"`
}

// BlogComment represents a comment on a blog post.
type BlogComment struct {
	ID        string `json:"id"`
	Content   string `json:"content"`
	Writer    string `json:"writer"`
	WriteDate string `json:"write_date"`
}

// NaverBlogResponse represents the response from Naver Blog API
type NaverBlogResponse struct {
	ResultCode    string `json:"resultCode"`
	ResultMessage string `json:"resultMessage"`
	PostList      []struct {
		LogNo            string `json:"logNo"`
		Title            string `json:"title"`
		CategoryNo       string `json:"categoryNo"`
		ParentCategoryNo string `json:"parentCategoryNo"`
		CommentCount     string `json:"commentCount"`
		ReadCount        string `json:"readCount"`
		AddDate          string `json:"addDate"`
	} `json:"postList"`
	CountPerPage string `json:"countPerPage"`
	TotalCount   string `json:"totalCount"`
}

// ì…€ë ‰í„° ìƒìˆ˜ ì •ì˜
const (
	writerSelectors         = ".nick_name, .blog_author .author_name, .author, .writer, .nickname, .blog_name, .blog_name, .nickname"
	dateSelectors           = ".se_time, .blog_header_info .date, ._postContents .post_info .date, .post_date, .date, .write_date, .se_publishDate, .date"
	contentSelectors        = ".se-main-container, .post_content, .se-component.se-text.se-section, .sect_dsc, .post_ct, #content-area .post_content, .se-module-text, .pcol1 .post_content, .se-main-container, .post-view"
	commentSelectors        = ".comment_area .comment_item, ._commentWrapper .comment_row, .comment_list .comment, .cmt_area .cmt_item, .comment_item"
	commentContentSelectors = ".comment_text, .text_comment, .cmt_text, .comment_text_box"
	commentWriterSelectors  = ".comment_nick, .author_name, .cmt_nick, .comment_nick_box"
	commentDateSelectors    = ".comment_date, .date, .cmt_date, .comment_date_box"
)

// ê²Œì‹œê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - ê°œì„ ëœ ë²„ì „
func GetBlogPostList(blogID string, page int) ([]BlogPost, error) {
	url := fmt.Sprintf("https://blog.naver.com/PostTitleListAsync.naver?blogId=%s&viewdate=&currentPage=%d&categoryNo=0&parentCategoryNo=0&countPerPage=5", blogID, page)

	resp, err := client.Get(url)
	if err != nil {
		return nil, fmt.Errorf("ê²Œì‹œê¸€ ëª©ë¡ ìš”ì²­ ì‹¤íŒ¨: %v", err)
	}
	defer resp.Body.Close()

	// ì‘ë‹µ ë³¸ë¬¸ ì½ê¸°
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("ì‘ë‹µ ì½ê¸° ì‹¤íŒ¨: %v", err)
	}

	// ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ë³€í™˜
	jsonStr := strings.ReplaceAll(string(body), "'", "\"")

	var blogResponse NaverBlogResponse
	if err := json.Unmarshal([]byte(jsonStr), &blogResponse); err != nil {
		return nil, fmt.Errorf("JSON íŒŒì‹± ì‹¤íŒ¨: %v", err)
	}

	if blogResponse.ResultCode != "S" {
		return nil, fmt.Errorf("API ì‘ë‹µ ì˜¤ë¥˜: %s", blogResponse.ResultMessage)
	}

	var posts []BlogPost
	for _, post := range blogResponse.PostList {
		posts = append(posts, BlogPost{
			ID:          post.LogNo,
			Title:       post.Title,
			WriteDate:   post.AddDate,
			OriginalURL: fmt.Sprintf("https://blog.naver.com/%s/%s", blogID, post.LogNo),
		})
	}

	if len(posts) == 0 {
		log.Printf("âš ï¸ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URL: %s", url)
	}

	return posts, nil
}

// ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ê°œì„ ëœ ë²„ì „
func GetBlogPostDetail(blogID string, articleID string) (BlogPost, error) {
	url := fmt.Sprintf("https://blog.naver.com/PostView.naver?blogId=%s&logNo=%s", blogID, articleID)

	resp, err := client.Get(url)
	if err != nil {
		return BlogPost{}, fmt.Errorf("ê²Œì‹œê¸€ ìƒì„¸ ë¡œë“œ ì‹¤íŒ¨: %v", err)
	}
	defer resp.Body.Close()

	doc, err := goquery.NewDocumentFromReader(resp.Body)
	if err != nil {
		return BlogPost{}, fmt.Errorf("HTML íŒŒì‹± ì‹¤íŒ¨: %v", err)
	}

	// script íƒœê·¸ ì œê±°
	doc.Find("script").Remove()

	// title íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ
	title := doc.Find("title").Text()
	// ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±° (ì˜ˆ: " : ë„¤ì´ë²„ ë¸”ë¡œê·¸")
	title = strings.Split(title, " : ë„¤ì´ë²„ ë¸”ë¡œê·¸")[0]

	// .se-main-container ë‚´ì˜ ì½˜í…ì¸ ë§Œ ì¶”ì¶œ
	content := doc.Find(".se-main-container").Text()

	// ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
	content = strings.Join(strings.Fields(content), " ")

	// ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
	content = strings.TrimSpace(content)

	blogPost := BlogPost{
		ID:          articleID,
		OriginalURL: url,
		Title:       title,
		Writer:      utils.FindFirstMatch(doc, writerSelectors),
		WriteDate:   utils.FindFirstMatch(doc, dateSelectors),
		Content:     content,
		Comments:    extractComments(doc),
	}

	if blogPost.Title == "" && blogPost.Content == "" {
		return blogPost, fmt.Errorf("ê²Œì‹œê¸€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
	}

	return blogPost, nil
}

// CrawlBlog performs the main crawling operation for a Naver blog
func CrawlBlog(blogID string, maxPages int) ([]BlogPost, error) {
	log.Printf("ğŸš€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '%s' í¬ë¡¤ë§ ì‹œì‘...", blogID)

	outputDir := "output_blog"
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		return nil, fmt.Errorf("ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: %v", err)
	}

	var allPosts []BlogPost
	var mu sync.Mutex

	for page := 1; page <= maxPages; page++ {
		detailedPostsOnPage, err := processPage(blogID, page, maxPages)
		if err != nil {
			log.Printf("âš ï¸ í˜ì´ì§€ %d ì²˜ë¦¬ ì‹¤íŒ¨: %v", page, err)
			continue
		}

		if len(detailedPostsOnPage) == 0 {
			continue
		}

		mu.Lock()
		allPosts = append(allPosts, detailedPostsOnPage...)
		mu.Unlock()

		if err := savePageResults(blogID, page, detailedPostsOnPage, outputDir); err != nil {
			log.Printf("âš ï¸ í˜ì´ì§€ %d ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", page, err)
		}
	}

	if len(allPosts) > 0 {
		if err := saveFullResults(blogID, allPosts, outputDir); err != nil {
			log.Printf("âš ï¸ ì „ì²´ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
		printResults(allPosts)
	} else {
		fmt.Println("âš ï¸ ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ë¸”ë¡œê·¸ IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
	}

	log.Printf("ğŸ‰ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '%s' í¬ë¡¤ë§ ì™„ë£Œ! ì´ %dê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘", blogID, len(allPosts))
	return allPosts, nil
}

// Helper functions

func extractComments(doc *goquery.Document) []BlogComment {
	var comments []BlogComment
	doc.Find(commentSelectors).Each(func(i int, s *goquery.Selection) {
		content := utils.CleanText(s.Find(commentContentSelectors).First().Text())
		if content != "" {
			comments = append(comments, BlogComment{
				ID:        fmt.Sprintf("%d", i+1),
				Content:   content,
				Writer:    utils.CleanText(s.Find(commentWriterSelectors).First().Text()),
				WriteDate: utils.CleanText(s.Find(commentDateSelectors).First().Text()),
			})
		}
	})
	return comments
}

func processPage(blogID string, page, maxPages int) ([]BlogPost, error) {
	log.Printf("ğŸ”„ %d/%d í˜ì´ì§€ ì²˜ë¦¬ ì¤‘...", page, maxPages)

	postsOnPage, err := GetBlogPostList(blogID, page)
	if err != nil {
		return nil, fmt.Errorf("ê²Œì‹œê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", err)
	}

	if len(postsOnPage) == 0 {
		return nil, fmt.Errorf("ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
	}

	var detailedPostsOnPage []BlogPost
	for i, post := range postsOnPage {
		log.Printf("  ğŸ“– %dí˜ì´ì§€ ê²Œì‹œê¸€ %d/%d ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì¤‘... (ID: %s)", page, i+1, len(postsOnPage), post.ID)

		detail, err := GetBlogPostDetail(blogID, post.ID)
		if err != nil {
			log.Printf("âš ï¸ ê²Œì‹œê¸€ %s ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", post.ID, err)
			continue
		}

		if detail.Title != "" || detail.Content != "" {
			detailedPostsOnPage = append(detailedPostsOnPage, detail)
		}
	}

	return detailedPostsOnPage, nil
}

func savePageResults(blogID string, page int, posts []BlogPost, outputDir string) error {
	timestamp := time.Now().Format("20060102_150405")
	pageFilename := filepath.Join(outputDir, fmt.Sprintf("blog_%s_page_%d_%s.json", blogID, page, timestamp))

	formattedPosts := formatPosts(posts)
	if err := utils.SaveToJSON(formattedPosts, pageFilename); err != nil {
		return fmt.Errorf("í˜ì´ì§€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
	}

	return nil
}

func saveFullResults(blogID string, posts []BlogPost, outputDir string) error {
	timestamp := time.Now().Format("20060102_150405")
	fullFilename := filepath.Join(outputDir, fmt.Sprintf("blog_%s_full_%s.json", blogID, timestamp))

	formattedPosts := formatPosts(posts)
	if err := utils.SaveToJSON(formattedPosts, fullFilename); err != nil {
		return fmt.Errorf("ì „ì²´ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
	}

	return nil
}

func formatPosts(posts []BlogPost) []map[string]interface{} {
	var formattedPosts []map[string]interface{}
	for _, post := range posts {
		formattedPosts = append(formattedPosts, map[string]interface{}{
			"title":   post.Title,
			"content": post.Content,
			"metadata": map[string]interface{}{
				"id":         post.ID,
				"writer":     post.Writer,
				"write_date": post.WriteDate,
				"url":        post.OriginalURL,
			},
			"comments": post.Comments,
		})
	}
	return formattedPosts
}

func printResults(posts []BlogPost) {
	fmt.Printf("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\n")
	for i, post := range posts {
		if i >= 5 {
			fmt.Printf("... ì™¸ %dê°œ ê²Œì‹œê¸€\n", len(posts)-5)
			break
		}
		fmt.Printf("ğŸ“Œ [%d] %s\n", i+1, post.Title)
		fmt.Printf("   ğŸ‘¤ %s | ğŸ“… %s | ğŸ’¬ %dê°œ ëŒ“ê¸€\n", post.Writer, post.WriteDate, len(post.Comments))
		fmt.Printf("   ğŸ“ %s...\n", utils.TruncateString(post.Content, 100))
		fmt.Println()
	}
}
